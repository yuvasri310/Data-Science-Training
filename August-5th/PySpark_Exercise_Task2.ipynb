{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Module 1: Setup & SparkSession Initialization"
      ],
      "metadata": {
        "id": "NAwuGlhctnJ_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "p9wpwV21tjQm"
      },
      "outputs": [],
      "source": [
        "!pip install -q pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import & Start Spark\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"BotCampus PySpark Practice\") \\\n",
        "    .master(\"local[*]\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "# Create DataFrame\n",
        "data = [\n",
        "    (\"Anjali\", \"Bangalore\", 24),\n",
        "    (\"Ravi\", \"Hyderabad\", 28),\n",
        "    (\"Kavya\", \"Delhi\", 22),\n",
        "    (\"Meena\", \"Chennai\", 25),\n",
        "    (\"Arjun\", \"Mumbai\", 30)\n",
        "]\n",
        "columns = [\"name\", \"city\", \"age\"]\n",
        "df = spark.createDataFrame(data, columns)"
      ],
      "metadata": {
        "id": "5kC5Tkvft156"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show schema and data\n",
        "df.printSchema()\n",
        "df.show()\n",
        "\n",
        "# Convert to RDD and show outputs\n",
        "rdd = df.rdd\n",
        "print(rdd.collect())\n",
        "print(rdd.map(lambda x: (x.name, x.age)).collect())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kokTYFmLt4k8",
        "outputId": "cb0cea41-b30c-42f4-fb52-67d08d20a52a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- name: string (nullable = true)\n",
            " |-- city: string (nullable = true)\n",
            " |-- age: long (nullable = true)\n",
            "\n",
            "+------+---------+---+\n",
            "|  name|     city|age|\n",
            "+------+---------+---+\n",
            "|Anjali|Bangalore| 24|\n",
            "|  Ravi|Hyderabad| 28|\n",
            "| Kavya|    Delhi| 22|\n",
            "| Meena|  Chennai| 25|\n",
            "| Arjun|   Mumbai| 30|\n",
            "+------+---------+---+\n",
            "\n",
            "[Row(name='Anjali', city='Bangalore', age=24), Row(name='Ravi', city='Hyderabad', age=28), Row(name='Kavya', city='Delhi', age=22), Row(name='Meena', city='Chennai', age=25), Row(name='Arjun', city='Mumbai', age=30)]\n",
            "[('Anjali', 24), ('Ravi', 28), ('Kavya', 22), ('Meena', 25), ('Arjun', 30)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Module 2: RDDs & Transformations"
      ],
      "metadata": {
        "id": "5Yq-LIEVt-uE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feedback = spark.sparkContext.parallelize([\n",
        "    \"Ravi from Bangalore loved the delivery\",\n",
        "    \"Meena from Hyderabad had a late order\",\n",
        "    \"Ajay from Pune liked the service\",\n",
        "    \"Anjali from Delhi faced UI issues\",\n",
        "    \"Rohit from Mumbai gave positive feedback\"\n",
        "])\n"
      ],
      "metadata": {
        "id": "yBJAW4fwuEp0"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Split each line into words (flatMap)\n",
        "words = feedback.flatMap(lambda line: line.lower().split())\n",
        "words.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mbb7WfiTuPLV",
        "outputId": "5c5c7ad3-d8e5-4b05-8ac0-b44d57fdb27e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ravi',\n",
              " 'from',\n",
              " 'bangalore',\n",
              " 'loved',\n",
              " 'the',\n",
              " 'delivery',\n",
              " 'meena',\n",
              " 'from',\n",
              " 'hyderabad',\n",
              " 'had',\n",
              " 'a',\n",
              " 'late',\n",
              " 'order',\n",
              " 'ajay',\n",
              " 'from',\n",
              " 'pune',\n",
              " 'liked',\n",
              " 'the',\n",
              " 'service',\n",
              " 'anjali',\n",
              " 'from',\n",
              " 'delhi',\n",
              " 'faced',\n",
              " 'ui',\n",
              " 'issues',\n",
              " 'rohit',\n",
              " 'from',\n",
              " 'mumbai',\n",
              " 'gave',\n",
              " 'positive',\n",
              " 'feedback']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove stop words (from, the, a, etc.)\n",
        "stop_words = {\"from\", \"the\", \"a\", \"an\", \"had\"}\n",
        "filtered_words = words.filter(lambda word: word not in stop_words)\n",
        "filtered_words.collect()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-QCL4WYIuQuA",
        "outputId": "5d477a75-7661-4a2e-ebc1-83534af9c814"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ravi',\n",
              " 'bangalore',\n",
              " 'loved',\n",
              " 'delivery',\n",
              " 'meena',\n",
              " 'hyderabad',\n",
              " 'late',\n",
              " 'order',\n",
              " 'ajay',\n",
              " 'pune',\n",
              " 'liked',\n",
              " 'service',\n",
              " 'anjali',\n",
              " 'delhi',\n",
              " 'faced',\n",
              " 'ui',\n",
              " 'issues',\n",
              " 'rohit',\n",
              " 'mumbai',\n",
              " 'gave',\n",
              " 'positive',\n",
              " 'feedback']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Count each word frequency using reduceByKey .\n",
        "word_counts = filtered_words.map(lambda word: (word, 1)).reduceByKey(lambda a, b: a + b)\n",
        "word_counts.collect()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qymTQFSBuSbB",
        "outputId": "758a5e05-3d34-4354-fecf-099ca746ab4f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('loved', 1),\n",
              " ('liked', 1),\n",
              " ('service', 1),\n",
              " ('anjali', 1),\n",
              " ('faced', 1),\n",
              " ('issues', 1),\n",
              " ('rohit', 1),\n",
              " ('mumbai', 1),\n",
              " ('positive', 1),\n",
              " ('feedback', 1),\n",
              " ('ravi', 1),\n",
              " ('bangalore', 1),\n",
              " ('delivery', 1),\n",
              " ('meena', 1),\n",
              " ('hyderabad', 1),\n",
              " ('late', 1),\n",
              " ('order', 1),\n",
              " ('ajay', 1),\n",
              " ('pune', 1),\n",
              " ('delhi', 1),\n",
              " ('ui', 1),\n",
              " ('gave', 1)]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "top_3_words = word_counts.takeOrdered(3, key=lambda x: -x[1])\n",
        "top_3_words\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g01a7jSpuUVj",
        "outputId": "0b165b5e-488c-4520-d6c1-66176876524f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('loved', 1), ('liked', 1), ('service', 1)]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Module 3: DataFrames & Transformation (With Joins)"
      ],
      "metadata": {
        "id": "jMV57461ulTM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col, when\n",
        "\n",
        "students = [\n",
        "    (\"Amit\", \"10-A\", 89),\n",
        "    (\"Kavya\", \"10-B\", 92),\n",
        "    (\"Anjali\", \"10-A\", 78),\n",
        "    (\"Rohit\", \"10-B\", 85),\n",
        "    (\"Sneha\", \"10-C\", 80)\n",
        "]\n",
        "attendance = [\n",
        "    (\"Amit\", 24),\n",
        "    (\"Kavya\", 22),\n",
        "    (\"Anjali\", 20),\n",
        "    (\"Rohit\", 25),\n",
        "    (\"Sneha\", 19)\n",
        "]\n",
        "df_students = spark.createDataFrame(students, [\"name\", \"section\", \"marks\"])\n",
        "df_attendance = spark.createDataFrame(attendance, [\"name\", \"days_present\"])"
      ],
      "metadata": {
        "id": "jyYAsWtDumXI"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Join both DataFrames on name .\n",
        "df_joined = df_students.join(df_attendance, \"name\")\n",
        "df_joined.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "98iD5oZ5wjAI",
        "outputId": "efc46d5a-cdf2-4324-de33-69913d21ced8"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-------+-----+------------+\n",
            "|  name|section|marks|days_present|\n",
            "+------+-------+-----+------------+\n",
            "|  Amit|   10-A|   89|          24|\n",
            "|Anjali|   10-A|   78|          20|\n",
            "| Kavya|   10-B|   92|          22|\n",
            "| Rohit|   10-B|   85|          25|\n",
            "| Sneha|   10-C|   80|          19|\n",
            "+------+-------+-----+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a new column: attendance_rate = days_present / 25 .\n",
        "df_final = df_joined.withColumn(\"attendance_rate\", col(\"days_present\") / 25)\n",
        "df_final.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4GPGnSnEwxzT",
        "outputId": "8211d517-56be-45cb-cee3-9fd5009981c6"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-------+-----+------------+---------------+\n",
            "|  name|section|marks|days_present|attendance_rate|\n",
            "+------+-------+-----+------------+---------------+\n",
            "|  Amit|   10-A|   89|          24|           0.96|\n",
            "|Anjali|   10-A|   78|          20|            0.8|\n",
            "| Kavya|   10-B|   92|          22|           0.88|\n",
            "| Rohit|   10-B|   85|          25|            1.0|\n",
            "| Sneha|   10-C|   80|          19|           0.76|\n",
            "+------+-------+-----+------------+---------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Grade students using when :A: >90, B: 80–90, C: <80.\n",
        "df_final = df_final.withColumn(\"grade\", when(col(\"marks\") > 90, \"A\")\n",
        "                                .when((col(\"marks\") <= 90) & (col(\"marks\") >= 80), \"B\")\n",
        "                                .otherwise(\"C\"))\n",
        "df_final.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IbUWODDPw15z",
        "outputId": "557c0d56-5ce6-47f9-8379-b00375d970ba"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-------+-----+------------+---------------+-----+\n",
            "|  name|section|marks|days_present|attendance_rate|grade|\n",
            "+------+-------+-----+------------+---------------+-----+\n",
            "|  Amit|   10-A|   89|          24|           0.96|    B|\n",
            "|Anjali|   10-A|   78|          20|            0.8|    C|\n",
            "| Kavya|   10-B|   92|          22|           0.88|    A|\n",
            "| Rohit|   10-B|   85|          25|            1.0|    B|\n",
            "| Sneha|   10-C|   80|          19|           0.76|    B|\n",
            "+------+-------+-----+------------+---------------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Filter students with good grades but poor attendance (<80%).\n",
        "df_filtered = df_final.filter((col(\"grade\").isin(\"A\", \"B\")) & (col(\"attendance_rate\") < 0.8))\n",
        "df_filtered.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RUyUx0nKw80w",
        "outputId": "eb80ec92-e743-49b8-8db6-c2b7fb77d42e"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-------+-----+------------+---------------+-----+\n",
            "| name|section|marks|days_present|attendance_rate|grade|\n",
            "+-----+-------+-----+------------+---------------+-----+\n",
            "|Sneha|   10-C|   80|          19|           0.76|    B|\n",
            "+-----+-------+-----+------------+---------------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Module 4: Ingest CSV & JSON, Save as Parquet"
      ],
      "metadata": {
        "id": "l4kqjHmExM58"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create CSV\n",
        "with open(\"employees.csv\", \"w\") as f:\n",
        "    f.write(\"\"\"emp_id,name,dept,city,salary\n",
        "101,Anil,IT,Bangalore,80000\n",
        "102,Kiran,HR,Mumbai,65000\n",
        "103,Deepa,Finance,Chennai,72000\n",
        "\"\"\")"
      ],
      "metadata": {
        "id": "mMHgb8SuxULo"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create JSON\n",
        "with open(\"employee.json\", \"w\") as f:\n",
        "    f.write(\"\"\"\n",
        "{\n",
        "\"id\": 201,\n",
        "\"name\": \"Nandini\",\n",
        "\"contact\": {\n",
        "    \"email\": \"nandi@example.com\",\n",
        "    \"city\": \"Hyderabad\"\n",
        "},\n",
        "\"skills\": [\"Python\", \"Spark\", \"SQL\"]\n",
        "}\n",
        "\"\"\")"
      ],
      "metadata": {
        "id": "nmBXpuTZxXFu"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load CSV\n",
        "df_csv = spark.read.option(\"header\", True).csv(\"employees.csv\", inferSchema=True)\n",
        "\n",
        "# Load JSON\n",
        "df_json = spark.read.option(\"multiline\", True).json(\"employee.json\")\n"
      ],
      "metadata": {
        "id": "9JuftmfPxYxt"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Flatten JSON\n",
        "from pyspark.sql.functions import col, explode\n",
        "\n",
        "df_flat = df_json.select(\n",
        "    col(\"id\"),\n",
        "    col(\"name\"),\n",
        "    col(\"contact.city\").alias(\"city\"),\n",
        "    explode(col(\"skills\")).alias(\"skill\")\n",
        ")\n"
      ],
      "metadata": {
        "id": "p2qaAisMxh1m"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save to Parquet partitioned by city\n",
        "df_csv.write.mode(\"overwrite\").partitionBy(\"city\").parquet(\"/content/emp_csv_parquet\")\n",
        "df_flat.write.mode(\"overwrite\").partitionBy(\"city\").parquet(\"/content/emp_json_parquet\")\n"
      ],
      "metadata": {
        "id": "c82zkDN-xkvM"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Module 5: Spark SQL with Temp Views"
      ],
      "metadata": {
        "id": "3ahXlhgWxnTe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_students.createOrReplaceTempView(\"students_view\")\n"
      ],
      "metadata": {
        "id": "9AGJ3xRZxm8A"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# a) Average marks per section\n",
        "spark.sql(\"SELECT section, AVG(marks) as avg_marks FROM students_view GROUP BY section\").show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rDctJPG_xvFT",
        "outputId": "d569e274-c845-4c5e-e14e-26287b5ba10a"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+---------+\n",
            "|section|avg_marks|\n",
            "+-------+---------+\n",
            "|   10-A|     83.5|\n",
            "|   10-B|     88.5|\n",
            "|   10-C|     80.0|\n",
            "+-------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# b) Top scorer per section\n",
        "spark.sql(\"\"\"SELECT section, name, marks FROM (SELECT *, RANK() OVER(PARTITION BY section ORDER BY marks DESC) as rank\n",
        "    FROM students_view) WHERE rank = 1\"\"\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3JVjDZNExw6C",
        "outputId": "3de0f826-ee2e-45e2-cdd2-a5846e9db869"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-----+-----+\n",
            "|section| name|marks|\n",
            "+-------+-----+-----+\n",
            "|   10-A| Amit|   89|\n",
            "|   10-B|Kavya|   92|\n",
            "|   10-C|Sneha|   80|\n",
            "+-------+-----+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# c) Count of students per grade\n",
        "spark.sql(\"\"\"SELECT CASE WHEN marks > 90 THEN 'A' WHEN marks BETWEEN 80 AND 90 THEN 'B'\n",
        "        ELSE 'C' END as grade,COUNT(*) as count FROM students_view\n",
        "        GROUP BY grade\"\"\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XedSpXElxyzk",
        "outputId": "983e29b2-72cd-478b-a943-41b2a3536062"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----+\n",
            "|grade|count|\n",
            "+-----+-----+\n",
            "|    B|    3|\n",
            "|    A|    1|\n",
            "|    C|    1|\n",
            "+-----+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# d) Students above average\n",
        "spark.sql(\"\"\"WITH avg_table AS (SELECT AVG(marks) as avg_marks FROM students_view)\n",
        "SELECT * FROM students_view, avg_table WHERE students_view.marks > avg_table.avg_marks\"\"\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QwQ39Ew2x8XU",
        "outputId": "d23354ff-7773-4495-d508-5a77e0e733c5"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-------+-----+---------+\n",
            "| name|section|marks|avg_marks|\n",
            "+-----+-------+-----+---------+\n",
            "| Amit|   10-A|   89|     84.8|\n",
            "|Kavya|   10-B|   92|     84.8|\n",
            "|Rohit|   10-B|   85|     84.8|\n",
            "+-----+-------+-----+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Module 6: Partitioned Write & Incremental Load"
      ],
      "metadata": {
        "id": "d-QWr-skyVQI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Full load\n",
        "df_students.write.mode(\"overwrite\").partitionBy(\"section\").parquet(\"/content/output/students\")\n",
        "\n",
        "# Incremental load\n",
        "df_inc = spark.createDataFrame([(\"Tejas\", \"10-A\", 91)], [\"name\", \"section\", \"marks\"])\n",
        "df_inc.write.mode(\"append\").partitionBy(\"section\").parquet(\"/content/output/students\")"
      ],
      "metadata": {
        "id": "bN_-bmS2ya-z"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List files\n",
        "import os\n",
        "print(\"Files in partitioned directory:\")\n",
        "print(os.listdir(\"/content/output/students\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nFMAiN_qydej",
        "outputId": "82c300a8-d63d-40b5-c7d1-cde282a22345"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files in partitioned directory:\n",
            "['._SUCCESS.crc', 'section=10-A', 'section=10-B', '_SUCCESS', 'section=10-C']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_10A = spark.read.parquet(\"/content/output/students/section=10-A\")\n",
        "df_10A.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F13dfJvZyicG",
        "outputId": "e924ff9f-e1aa-418f-e7e7-817418a14575"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-----+\n",
            "|  name|marks|\n",
            "+------+-----+\n",
            "|Anjali|   78|\n",
            "| Tejas|   91|\n",
            "|  Amit|   89|\n",
            "+------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Module 7: ETL Pipeline – End to End"
      ],
      "metadata": {
        "id": "VfLG51Klym4I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create CSV\n",
        "with open(\"raw_emp.csv\", \"w\") as f:\n",
        "    f.write(\"\"\"emp_id,name,dept,salary,bonus\n",
        "1,Arjun,IT,75000,5000\n",
        "2,Kavya,HR,62000,\n",
        "3,Sneha,Finance,68000,4000\n",
        "4,Ramesh,Sales,58000,\n",
        "\"\"\")\n",
        "df_raw = spark.read.option(\"header\", True).option(\"inferSchema\", True).csv(\"raw_emp.csv\")"
      ],
      "metadata": {
        "id": "235HuiloylEd"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#fill bonus\n",
        "df_filled = df_raw.fillna({\"bonus\": 2000})\n",
        "df_filled.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fUHM37Yby3l2",
        "outputId": "a3592e2c-9082-4edb-82ba-234a1a96267b"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+------+-------+------+-----+\n",
            "|emp_id|  name|   dept|salary|bonus|\n",
            "+------+------+-------+------+-----+\n",
            "|     1| Arjun|     IT| 75000| 5000|\n",
            "|     2| Kavya|     HR| 62000| 2000|\n",
            "|     3| Sneha|Finance| 68000| 4000|\n",
            "|     4|Ramesh|  Sales| 58000| 2000|\n",
            "+------+------+-------+------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add total_ctc\n",
        "df_final = df_filled.withColumn(\"total_ctc\", col(\"salary\") + col(\"bonus\"))\n",
        "df_final.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W8nIzhBhzBz2",
        "outputId": "77ecbe32-0983-4d20-a3e2-5633c2cc3498"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+------+-------+------+-----+---------+\n",
            "|emp_id|  name|   dept|salary|bonus|total_ctc|\n",
            "+------+------+-------+------+-----+---------+\n",
            "|     1| Arjun|     IT| 75000| 5000|    80000|\n",
            "|     2| Kavya|     HR| 62000| 2000|    64000|\n",
            "|     3| Sneha|Finance| 68000| 4000|    72000|\n",
            "|     4|Ramesh|  Sales| 58000| 2000|    60000|\n",
            "+------+------+-------+------+-----+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter > 65k\n",
        "df_filtered = df_final.filter(col(\"total_ctc\") > 65000)\n",
        "df_filtered.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X0CG1vS8zDWE",
        "outputId": "71a973d1-c668-484f-b3db-68bab4ee8a4b"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-----+-------+------+-----+---------+\n",
            "|emp_id| name|   dept|salary|bonus|total_ctc|\n",
            "+------+-----+-------+------+-----+---------+\n",
            "|     1|Arjun|     IT| 75000| 5000|    80000|\n",
            "|     3|Sneha|Finance| 68000| 4000|    72000|\n",
            "+------+-----+-------+------+-----+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save to JSON\n",
        "df_filtered.write.mode(\"overwrite\").json(\"/content/etl_output/json\")\n",
        "# Save to Parquet partitioned by dept\n",
        "df_filtered.write.mode(\"overwrite\").partitionBy(\"dept\").parquet(\"/content/etl_output/parquet\")"
      ],
      "metadata": {
        "id": "rLdbkF34zEwO"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"employees.csv\")\n",
        "files.download(\"employee.json\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "n7LN5OZmzQZi",
        "outputId": "ce1bbf62-2b15-4fe5-8d3d-3b6a80cf6572"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_53262ddd-05dd-4dae-a8f6-cb0a028f2c3d\", \"employees.csv\", 115)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_38291c42-523f-4cdc-b34a-5adefdfed98f\", \"employee.json\", 146)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}